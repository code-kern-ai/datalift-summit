{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the labeled data\n",
    "\n",
    "We are using the **kern export format** here, which is a simple json that can be read from pandas directly. \n",
    "\n",
    "If you're using a csv from an Excel export, just modify this code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"labeled data\\datascienceweekly_labeled.json\"\n",
    "df = pd.read_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"__Interesting__WEAK_SUPERVISION\", \"__Interesting__WEAK_SUPERVISION__confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-28 23:21:02+00:00</td>\n",
       "      <td>Editor Picks</td>\n",
       "      <td>Beyond interpretability: developing a language...</td>\n",
       "      <td>AI will continue becoming more complex, bigger...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-21 22:34:45+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Bad ML Abstractions I (Generative vs Discrimin...</td>\n",
       "      <td>This post is part of a series on bad abstracti...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Exploring Plain Vision Transformer Backbones f...</td>\n",
       "      <td>We explore the plain, non-hierarchical Vision ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Are we being too harsh on junior candidates? [...</td>\n",
       "      <td>As part of our hiring process for ML Engineers...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-25 02:50:51+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Sentiment Analysis on News Headlines: Classic ...</td>\n",
       "      <td>An explanatory guide to develop a binary class...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          newsletter                      date  \\\n",
       "0  datascienceweekly 2022-04-28 23:21:02+00:00   \n",
       "1  datascienceweekly 2022-04-21 22:34:45+00:00   \n",
       "2  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "3  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "4  datascienceweekly 2022-03-25 02:50:51+00:00   \n",
       "\n",
       "                            topic  \\\n",
       "0                    Editor Picks   \n",
       "1  Data Science Articles & Videos   \n",
       "2  Data Science Articles & Videos   \n",
       "3  Data Science Articles & Videos   \n",
       "4  Data Science Articles & Videos   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Beyond interpretability: developing a language...   \n",
       "1  Bad ML Abstractions I (Generative vs Discrimin...   \n",
       "2  Exploring Plain Vision Transformer Backbones f...   \n",
       "3  Are we being too harsh on junior candidates? [...   \n",
       "4  Sentiment Analysis on News Headlines: Classic ...   \n",
       "\n",
       "                                                body __Interesting__MANUAL  \n",
       "0  AI will continue becoming more complex, bigger...                   yes  \n",
       "1  This post is part of a series on bad abstracti...                    no  \n",
       "2  We explore the plain, non-hierarchical Vision ...                   yes  \n",
       "3  As part of our hiring process for ML Engineers...                   yes  \n",
       "4  An explanatory guide to develop a binary class...                    no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Moe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# required for WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# required for... well stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text_cols = [\"topic\", \"headline\", \"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"topic\", \"headline\", \"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: \"\".join([char for char in x if char not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmaziting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: [wnl.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    df.loc[i,\"full_text\"] = \" \".join(row[\"topic\"] + row[\"headline\"] + row[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-28 23:21:02+00:00</td>\n",
       "      <td>[editor, pick]</td>\n",
       "      <td>[beyond, interpretability, developing, languag...</td>\n",
       "      <td>[ai, continue, becoming, complex, bigger, smar...</td>\n",
       "      <td>yes</td>\n",
       "      <td>editor pick beyond interpretability developing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-21 22:34:45+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[bad, ml, abstraction, generative, v, discrimi...</td>\n",
       "      <td>[post, part, series, bad, abstraction, machine...</td>\n",
       "      <td>no</td>\n",
       "      <td>data science article video bad ml abstraction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[exploring, plain, vision, transformer, backbo...</td>\n",
       "      <td>[explore, plain, nonhierarchical, vision, tran...</td>\n",
       "      <td>yes</td>\n",
       "      <td>data science article video exploring plain vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[harsh, junior, candidate, reddit, discussion]</td>\n",
       "      <td>[part, hiring, process, ml, engineer, looking,...</td>\n",
       "      <td>yes</td>\n",
       "      <td>data science article video harsh junior candid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-25 02:50:51+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[sentiment, analysis, news, headline, classic,...</td>\n",
       "      <td>[explanatory, guide, develop, binary, classifi...</td>\n",
       "      <td>no</td>\n",
       "      <td>data science article video sentiment analysis ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          newsletter                      date  \\\n",
       "0  datascienceweekly 2022-04-28 23:21:02+00:00   \n",
       "1  datascienceweekly 2022-04-21 22:34:45+00:00   \n",
       "2  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "3  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "4  datascienceweekly 2022-03-25 02:50:51+00:00   \n",
       "\n",
       "                             topic  \\\n",
       "0                   [editor, pick]   \n",
       "1  [data, science, article, video]   \n",
       "2  [data, science, article, video]   \n",
       "3  [data, science, article, video]   \n",
       "4  [data, science, article, video]   \n",
       "\n",
       "                                            headline  \\\n",
       "0  [beyond, interpretability, developing, languag...   \n",
       "1  [bad, ml, abstraction, generative, v, discrimi...   \n",
       "2  [exploring, plain, vision, transformer, backbo...   \n",
       "3     [harsh, junior, candidate, reddit, discussion]   \n",
       "4  [sentiment, analysis, news, headline, classic,...   \n",
       "\n",
       "                                                body __Interesting__MANUAL  \\\n",
       "0  [ai, continue, becoming, complex, bigger, smar...                   yes   \n",
       "1  [post, part, series, bad, abstraction, machine...                    no   \n",
       "2  [explore, plain, nonhierarchical, vision, tran...                   yes   \n",
       "3  [part, hiring, process, ml, engineer, looking,...                   yes   \n",
       "4  [explanatory, guide, develop, binary, classifi...                    no   \n",
       "\n",
       "                                           full_text  \n",
       "0  editor pick beyond interpretability developing...  \n",
       "1  data science article video bad ml abstraction ...  \n",
       "2  data science article video exploring plain vis...  \n",
       "3  data science article video harsh junior candid...  \n",
       "4  data science article video sentiment analysis ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer().fit(df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_matrix = vectorizer.transform(df['full_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('onetask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a8dd3a8ce1b4c991bd9fc20ecbd33bb3a991b4d95e67424ec48b6633f11a8d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
