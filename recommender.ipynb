{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the labeled data\n",
    "\n",
    "We are using the **kern export format** here, which is a simple json that can be read from pandas directly. \n",
    "\n",
    "If you're using a csv from an Excel export, just modify this code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"labeled data\\datascienceweekly_labeled.json\"\n",
    "original_df = pd.read_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = original_df.drop(columns=[\"__Interesting__WEAK_SUPERVISION\", \"__Interesting__WEAK_SUPERVISION__confidence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-28 23:21:02+00:00</td>\n",
       "      <td>Editor Picks</td>\n",
       "      <td>Beyond interpretability: developing a language...</td>\n",
       "      <td>AI will continue becoming more complex, bigger...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-21 22:34:45+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Bad ML Abstractions I (Generative vs Discrimin...</td>\n",
       "      <td>This post is part of a series on bad abstracti...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Exploring Plain Vision Transformer Backbones f...</td>\n",
       "      <td>We explore the plain, non-hierarchical Vision ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Are we being too harsh on junior candidates? [...</td>\n",
       "      <td>As part of our hiring process for ML Engineers...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-25 02:50:51+00:00</td>\n",
       "      <td>Data Science Articles &amp; Videos</td>\n",
       "      <td>Sentiment Analysis on News Headlines: Classic ...</td>\n",
       "      <td>An explanatory guide to develop a binary class...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          newsletter                      date  \\\n",
       "0  datascienceweekly 2022-04-28 23:21:02+00:00   \n",
       "1  datascienceweekly 2022-04-21 22:34:45+00:00   \n",
       "2  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "3  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "4  datascienceweekly 2022-03-25 02:50:51+00:00   \n",
       "\n",
       "                            topic  \\\n",
       "0                    Editor Picks   \n",
       "1  Data Science Articles & Videos   \n",
       "2  Data Science Articles & Videos   \n",
       "3  Data Science Articles & Videos   \n",
       "4  Data Science Articles & Videos   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Beyond interpretability: developing a language...   \n",
       "1  Bad ML Abstractions I (Generative vs Discrimin...   \n",
       "2  Exploring Plain Vision Transformer Backbones f...   \n",
       "3  Are we being too harsh on junior candidates? [...   \n",
       "4  Sentiment Analysis on News Headlines: Classic ...   \n",
       "\n",
       "                                                body __Interesting__MANUAL  \n",
       "0  AI will continue becoming more complex, bigger...                   yes  \n",
       "1  This post is part of a series on bad abstracti...                    no  \n",
       "2  We explore the plain, non-hierarchical Vision ...                   yes  \n",
       "3  As part of our hiring process for ML Engineers...                   yes  \n",
       "4  An explanatory guide to develop a binary class...                    no  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Moe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# required for WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# required for... well stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text_cols = [\"topic\", \"headline\", \"body\"]\n",
    "df = original_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: \"\".join([char for char in x if char not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmaziting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(lambda x: [wnl.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO could be done easier with df.apply\n",
    "for i, row in df.iterrows():\n",
    "    df.loc[i,\"full_text\"] = \" \".join(row[\"topic\"] + row[\"headline\"] + row[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-28 23:21:02+00:00</td>\n",
       "      <td>[editor, pick]</td>\n",
       "      <td>[beyond, interpretability, developing, languag...</td>\n",
       "      <td>[ai, continue, becoming, complex, bigger, smar...</td>\n",
       "      <td>yes</td>\n",
       "      <td>editor pick beyond interpretability developing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-21 22:34:45+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[bad, ml, abstraction, generative, v, discrimi...</td>\n",
       "      <td>[post, part, series, bad, abstraction, machine...</td>\n",
       "      <td>no</td>\n",
       "      <td>data science article video bad ml abstraction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[exploring, plain, vision, transformer, backbo...</td>\n",
       "      <td>[explore, plain, nonhierarchical, vision, tran...</td>\n",
       "      <td>yes</td>\n",
       "      <td>data science article video exploring plain vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-31 23:12:31+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[harsh, junior, candidate, reddit, discussion]</td>\n",
       "      <td>[part, hiring, process, ml, engineer, looking,...</td>\n",
       "      <td>yes</td>\n",
       "      <td>data science article video harsh junior candid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-25 02:50:51+00:00</td>\n",
       "      <td>[data, science, article, video]</td>\n",
       "      <td>[sentiment, analysis, news, headline, classic,...</td>\n",
       "      <td>[explanatory, guide, develop, binary, classifi...</td>\n",
       "      <td>no</td>\n",
       "      <td>data science article video sentiment analysis ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          newsletter                      date  \\\n",
       "0  datascienceweekly 2022-04-28 23:21:02+00:00   \n",
       "1  datascienceweekly 2022-04-21 22:34:45+00:00   \n",
       "2  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "3  datascienceweekly 2022-03-31 23:12:31+00:00   \n",
       "4  datascienceweekly 2022-03-25 02:50:51+00:00   \n",
       "\n",
       "                             topic  \\\n",
       "0                   [editor, pick]   \n",
       "1  [data, science, article, video]   \n",
       "2  [data, science, article, video]   \n",
       "3  [data, science, article, video]   \n",
       "4  [data, science, article, video]   \n",
       "\n",
       "                                            headline  \\\n",
       "0  [beyond, interpretability, developing, languag...   \n",
       "1  [bad, ml, abstraction, generative, v, discrimi...   \n",
       "2  [exploring, plain, vision, transformer, backbo...   \n",
       "3     [harsh, junior, candidate, reddit, discussion]   \n",
       "4  [sentiment, analysis, news, headline, classic,...   \n",
       "\n",
       "                                                body __Interesting__MANUAL  \\\n",
       "0  [ai, continue, becoming, complex, bigger, smar...                   yes   \n",
       "1  [post, part, series, bad, abstraction, machine...                    no   \n",
       "2  [explore, plain, nonhierarchical, vision, tran...                   yes   \n",
       "3  [part, hiring, process, ml, engineer, looking,...                   yes   \n",
       "4  [explanatory, guide, develop, binary, classifi...                    no   \n",
       "\n",
       "                                           full_text  \n",
       "0  editor pick beyond interpretability developing...  \n",
       "1  data science article video bad ml abstraction ...  \n",
       "2  data science article video exploring plain vis...  \n",
       "3  data science article video harsh junior candid...  \n",
       "4  data science article video sentiment analysis ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer().fit(df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_matrix = vectorizer.transform(df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(transformed_matrix, transformed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_from_headline(df, headline, cosine_sim = cosine_sim):\n",
    "    print(\"looking for similar articles to:\\n\", headline)\n",
    "    recommended_articles = []\n",
    "    idx = df[df[\"headline\"] == headline].index[0]\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "    top_10_indices = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    for i in top_10_indices:\n",
    "        recommended_articles.append(list(df['headline'])[i])\n",
    "        \n",
    "    return recommended_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for similar articles to:  Beyond interpretability: developing a language to shape our relationships with AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What’s wrong with “explainable A.I.”',\n",
       " 'On NYT Magazine on AI: Resist the Urge to be Impressed',\n",
       " 'Announcing the 2022 AI Index Report',\n",
       " 'The Weird and Wonderful World of AI Art',\n",
       " \"What's next for AlphaFold and the AI protein-folding revolution\",\n",
       " 'Expert opinion: Regulating AI in Europe',\n",
       " 'Andrew Ng: Unbiggen AI',\n",
       " 'Anatomy of an AI System',\n",
       " 'How Does AI Improve Human Decision-Making? Evidence from the AI-Powered Go Program',\n",
       " \"ICLR Conference's First Blogpost Track Experiment was a great success with 20 accepted posts\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_from_headline(original_df, original_df.iloc[0].headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_from_vector(original_df, vec1, transformed_matrix = transformed_matrix):\n",
    "    recommended_articles = []\n",
    "    similarity_matrix = cosine_similarity(vec1, transformed_matrix)\n",
    "    scores = pd.Series(similarity_matrix[0]).sort_values(ascending = False)\n",
    "    top_10_indices = list(scores.iloc[1:11].index)\n",
    "    for i in top_10_indices:\n",
    "        recommended_articles.append(list(original_df['headline'])[i])\n",
    "    return recommended_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the \"interesting\" vector\n",
    "interesting_idxs = original_df[original_df[\"__Interesting__MANUAL\"] == \"yes\"].index\n",
    "\n",
    "# average the \"uninteresting\" vector\n",
    "uninteresting_idxs = original_df[original_df[\"__Interesting__MANUAL\"] == \"no\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moe\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data Science at Shopify',\n",
       " 'Probability Distributions To Be Aware Of For Data Science (With Code)',\n",
       " 'Faking It: How to Simulate Complex Data Generation Processes in R, Tidyverse Edition',\n",
       " 'A visual introduction to machine learning',\n",
       " 'Everything gets a package? Yes, everything gets a package.',\n",
       " 'Data Observability vs. Data Testing: Everything You Need to Know',\n",
       " 'How to Structure a Data Science Project for Readability and Transparency',\n",
       " 'Data salaries at FAANG companies in 2022',\n",
       " 'Hungryroot is looking for a Data Scientist to join our growing Data Team. As a Data Scientist, you will work closely with other Data Scientists and Data Engineers to develop various Machine Learning models that power Hungryroot and it’s AI functions. These models include traditional forecasting models, as well as more industry-specific optimization challenges.',\n",
       " 'Hungryroot is looking for a Data Scientist to join our growing Data Team. As a Data Scientist, you will work closely with other Data Scientists and Data Engineers to develop various Machine Learning models that power Hungryroot and it’s AI functions. These models include traditional forecasting models, as well as more industry-specific optimization challenges.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_from_vector(original_df, transformed_matrix[uninteresting_idxs].mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('onetask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a8dd3a8ce1b4c991bd9fc20ecbd33bb3a991b4d95e67424ec48b6633f11a8d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
