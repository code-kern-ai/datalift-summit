{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedders.classification.contextual import TransformerSentenceEmbedder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Raw Data\n",
    "For the Model we use the embedders library which make embedding generation really easy to use. (alternatively you can for example use \"sentence-transformers\")\n",
    "\n",
    "We are also using the **kern export format** here, which is a simple json that can be read from pandas directly. \n",
    "\n",
    "If you're using a csv from an Excel export, just modify this code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TransformerSentenceEmbedder(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../03_TrainingData/labeled_data_v1.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO to get all the context information we have to merge headline and body\n",
    "df[\"merged_texts\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedd the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO embedd the \"merged_texts\" with the previously loaded embedder\n",
    "embeddings = embedder#.?\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the option to save the embeddings so we don't need to re-calculate them for the backend later\n",
    "np.save(\"embeddings\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations using Vector Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "INTERESTING_LABEL_ATTRIBUTE = \"__Interesting__MANUAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO average the interesting vector\n",
    "interesting_idxs = df[...].index\n",
    "interesting_vector_avg = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO calculate the distances to the unlabeled data\n",
    "non_labeled_idxs = df[...].index\n",
    "dist_to_unlabeled = cdist(..., ..., metric=...)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the indices ascending\n",
    "sorted_unlabeled_idxs = dist_to_unlabeled.argsort()\n",
    "\n",
    "# translate them back to the original dataframe\n",
    "sorted_original_idxs = non_labeled_idxs[sorted_unlabeled_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_recommendations = df.loc[sorted_original_idxs[0:10]]\n",
    "top_10_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics covered by the article\n",
    "There are some problems when it comes to classifying topics in this setting. The most dominant one is that we don't know if the topics we selected are even all the topics that exist. For that we'd have to label every datapoint and also make sure that in the future there are no topics coming up that weren't in the training. Second, this data is rather unbalanced. We will not deal with these problems here and continue with our baseline usecase.\n",
    "\n",
    "Instead we will choose the topics that we want to have classified and which have enough support. We then introduce a \"catch-all\" class, where we map all other labels to.\n",
    "\n",
    "We will split the data into train and test set, train the model, and then evaluate it very quickly. We will not go into too much detail of the whole pipeline (it takes companies months to make sense of their data and models!) as this is not the aim of this workshop.\n",
    "\n",
    "After that we train on the whole available labeled data, predict with a set threshold and save the results to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TOPIC_LABEL_ATTRIBUTE = \"__Topic__MANUAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the labeled instances\n",
    "labeled_idxs = df[~df[TOPIC_LABEL_ATTRIBUTE].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look what labels have enough support\n",
    "df.loc[labeled_idxs][TOPIC_LABEL_ATTRIBUTE].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the labels that have enough support\n",
    "topics = [\"big tech\", ...]\n",
    "# TODO filter the labeled_df to these topics\n",
    "labeled_df = df.loc[labeled_idxs]\n",
    "labeled_df = labeled_df[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO split the training and test idxs\n",
    "train_idx, test_idx = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings[train_idx]\n",
    "X_test = embeddings[test_idx]\n",
    "y_train = df.loc[train_idx][TOPIC_LABEL_ATTRIBUTE]\n",
    "y_test = df.loc[test_idx][TOPIC_LABEL_ATTRIBUTE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate a classifier\n",
    "We can simulate the classification layer of a typical BERT pipeline with a LogisticRegression sklearn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fit the classifier\n",
    "clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Train on the whole available data now\n",
    "clf = LogisticRegression().fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get the unlabeled data\n",
    "unlabeled_df = ...\n",
    "unlabeled_idxs = unlabeled_df.index\n",
    "\n",
    "X = embeddings[unlabeled_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with a threshold\n",
    "THRESHOLD = 0.75\n",
    "pred_idx, pred_class = np.where(probs > THRESHOLD)\n",
    "# TODO translate the idxs to class names using a clf attribute\n",
    "pred_class_text = list(map(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the catch all class \"Unknown\"\n",
    "df[\"topic\"] = \"Unknown\"\n",
    "df.loc[labeled_df.index,\"topic\"] = df.loc[labeled_df.index][TOPIC_LABEL_ATTRIBUTE]\n",
    "df.loc[pred_idx,\"topic\"] = pred_class_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the topic distribution\n",
    "df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data with predicted topics to disk\n",
    "df[['newsletter', 'date', 'headline', 'body', INTERESTING_LABEL_ATTRIBUTE, 'merged_texts', 'topic']].to_csv(\"output.csv\", index=False, quoting=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('onetask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a8dd3a8ce1b4c991bd9fc20ecbd33bb3a991b4d95e67424ec48b6633f11a8d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
