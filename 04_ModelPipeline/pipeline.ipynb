{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedders.classification.contextual import TransformerSentenceEmbedder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Raw Data\n",
    "For the Model we use the embedders library which make embedding generation really easy to use. (alternatively you can for example use \"sentence-transformers\")\n",
    "\n",
    "We are also using the **kern export format** here, which is a simple json that can be read from pandas directly. \n",
    "\n",
    "If you're using a csv from an Excel export, just modify this code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name C:\\Users\\Moe/.cache\\torch\\sentence_transformers\\distilbert-base-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\Moe/.cache\\torch\\sentence_transformers\\distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedder = TransformerSentenceEmbedder(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"labeled_data_v1.json\"\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "      <th>__Interesting__WEAK_SUPERVISION</th>\n",
       "      <th>__Interesting__WEAK_SUPERVISION__confidence</th>\n",
       "      <th>__Topic__MANUAL</th>\n",
       "      <th>__Topic__WEAK_SUPERVISION</th>\n",
       "      <th>__Topic__WEAK_SUPERVISION__confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Box of Amazing</td>\n",
       "      <td>2022-05-08 06:01:12+00:00</td>\n",
       "      <td>Refind – Get smarter every day</td>\n",
       "      <td>Every day we pick 7 links from around the web ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Box of Amazing</td>\n",
       "      <td>2022-05-08 06:01:12+00:00</td>\n",
       "      <td>Fast, Cheap, and Out of Control: Inside Shein’...</td>\n",
       "      <td>Last fall, in the stagnation of pandemic life,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Box of Amazing</td>\n",
       "      <td>2022-05-08 06:01:12+00:00</td>\n",
       "      <td>Pity the Billionaire, Marc Andreessen Edition</td>\n",
       "      <td>Silicon Valley’s oligarch class can’t stop fee...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Box of Amazing</td>\n",
       "      <td>2022-05-08 06:01:12+00:00</td>\n",
       "      <td>Inside Elon Musk’s Big Plans for Twitter</td>\n",
       "      <td>Here’s what Mr. Musk is projecting for Twitter...</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>social media</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Box of Amazing</td>\n",
       "      <td>2022-05-08 06:01:12+00:00</td>\n",
       "      <td>A visit to the human factory</td>\n",
       "      <td>Will Jackson, CEO of robotics company Engineer...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       newsletter                       date  \\\n",
       "0  Box of Amazing  2022-05-08 06:01:12+00:00   \n",
       "1  Box of Amazing  2022-05-08 06:01:12+00:00   \n",
       "2  Box of Amazing  2022-05-08 06:01:12+00:00   \n",
       "3  Box of Amazing  2022-05-08 06:01:12+00:00   \n",
       "4  Box of Amazing  2022-05-08 06:01:12+00:00   \n",
       "\n",
       "                                            headline  \\\n",
       "0                     Refind – Get smarter every day   \n",
       "1  Fast, Cheap, and Out of Control: Inside Shein’...   \n",
       "2      Pity the Billionaire, Marc Andreessen Edition   \n",
       "3           Inside Elon Musk’s Big Plans for Twitter   \n",
       "4                       A visit to the human factory   \n",
       "\n",
       "                                                body __Interesting__MANUAL  \\\n",
       "0  Every day we pick 7 links from around the web ...                  None   \n",
       "1  Last fall, in the stagnation of pandemic life,...                  None   \n",
       "2  Silicon Valley’s oligarch class can’t stop fee...                  None   \n",
       "3  Here’s what Mr. Musk is projecting for Twitter...                    no   \n",
       "4  Will Jackson, CEO of robotics company Engineer...                  None   \n",
       "\n",
       "  __Interesting__WEAK_SUPERVISION __Interesting__WEAK_SUPERVISION__confidence  \\\n",
       "0                            None                                        None   \n",
       "1                            None                                        None   \n",
       "2                            None                                        None   \n",
       "3                            None                                        None   \n",
       "4                            None                                        None   \n",
       "\n",
       "  __Topic__MANUAL __Topic__WEAK_SUPERVISION  \\\n",
       "0            None                      None   \n",
       "1            None                      None   \n",
       "2            None                      None   \n",
       "3    social media                      None   \n",
       "4            None                      None   \n",
       "\n",
       "  __Topic__WEAK_SUPERVISION__confidence  \n",
       "0                                  None  \n",
       "1                                  None  \n",
       "2                                  None  \n",
       "3                                  None  \n",
       "4                                  None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the context information we have to merge headline and body\n",
    "df[\"merged_texts\"] = df[\"headline\"] + \". \"+ df[\"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedd the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, might take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches ...: 100%|██████████| 5/5 [00:25<00:00,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.array(embedder.transform(df[\"merged_texts\"].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have the option to save the embeddings so you don't need to re-calculate them\n",
    "np.save(\"embeddings\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations using Vector Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the interesting vector\n",
    "interesting_idxs = df[df[\"__Interesting__MANUAL\"] == \"yes\"].index\n",
    "interesting_vector_avg = embeddings[interesting_idxs].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distances to the unlabeled data\n",
    "non_labeled_idxs = df[df[\"__Interesting__MANUAL\"].isnull()].index\n",
    "dist_to_unlabeled = cdist(interesting_vector_avg.reshape(1,-1), embeddings[non_labeled_idxs], metric=\"cosine\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the indices ascending\n",
    "sorted_unlabeled_idxs = dist_to_unlabeled.argsort()\n",
    "\n",
    "# translate them back to the original dataframe\n",
    "sorted_original_idxs = non_labeled_idxs[sorted_unlabeled_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsletter</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>__Interesting__MANUAL</th>\n",
       "      <th>__Interesting__WEAK_SUPERVISION</th>\n",
       "      <th>__Interesting__WEAK_SUPERVISION__confidence</th>\n",
       "      <th>__Topic__MANUAL</th>\n",
       "      <th>__Topic__WEAK_SUPERVISION</th>\n",
       "      <th>__Topic__WEAK_SUPERVISION__confidence</th>\n",
       "      <th>merged_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-21 22:34:45+00:00</td>\n",
       "      <td>Real World Recommendation System - Part 1</td>\n",
       "      <td>Training a collaborative filtering based recom...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Real World Recommendation System - Part 1. Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>TLDR</td>\n",
       "      <td>2022-05-04 10:19:09+00:00</td>\n",
       "      <td>Meta has built a massive new language AI—and i...</td>\n",
       "      <td>Meta's AI lab has created a new language model...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Meta has built a massive new language AI—and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-03 23:50:48+00:00</td>\n",
       "      <td>Weaviate Podcast #9: Karen Beckers about the r...</td>\n",
       "      <td>Karen Beckers, Data Scientist from Squadra Mac...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Weaviate Podcast #9: Karen Beckers about the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-03-17 22:52:02+00:00</td>\n",
       "      <td>Building systems to securely reason over priva...</td>\n",
       "      <td>People today rely on AI systems such as assist...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Building systems to securely reason over priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>datascienceweekly</td>\n",
       "      <td>2022-04-28 23:21:02+00:00</td>\n",
       "      <td>Data Science at Stitch Fix</td>\n",
       "      <td>Podcast Interview with Olivia Liao, Senior Dir...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science at Stitch Fix. Podcast Interview ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            newsletter                       date  \\\n",
       "98   datascienceweekly  2022-04-21 22:34:45+00:00   \n",
       "422               TLDR  2022-05-04 10:19:09+00:00   \n",
       "244  datascienceweekly  2022-03-03 23:50:48+00:00   \n",
       "203  datascienceweekly  2022-03-17 22:52:02+00:00   \n",
       "82   datascienceweekly  2022-04-28 23:21:02+00:00   \n",
       "\n",
       "                                              headline  \\\n",
       "98           Real World Recommendation System - Part 1   \n",
       "422  Meta has built a massive new language AI—and i...   \n",
       "244  Weaviate Podcast #9: Karen Beckers about the r...   \n",
       "203  Building systems to securely reason over priva...   \n",
       "82                          Data Science at Stitch Fix   \n",
       "\n",
       "                                                  body __Interesting__MANUAL  \\\n",
       "98   Training a collaborative filtering based recom...                  None   \n",
       "422  Meta's AI lab has created a new language model...                  None   \n",
       "244  Karen Beckers, Data Scientist from Squadra Mac...                  None   \n",
       "203  People today rely on AI systems such as assist...                  None   \n",
       "82   Podcast Interview with Olivia Liao, Senior Dir...                  None   \n",
       "\n",
       "    __Interesting__WEAK_SUPERVISION  \\\n",
       "98                             None   \n",
       "422                            None   \n",
       "244                            None   \n",
       "203                            None   \n",
       "82                             None   \n",
       "\n",
       "    __Interesting__WEAK_SUPERVISION__confidence __Topic__MANUAL  \\\n",
       "98                                         None            None   \n",
       "422                                        None            None   \n",
       "244                                        None            None   \n",
       "203                                        None            None   \n",
       "82                                         None            None   \n",
       "\n",
       "    __Topic__WEAK_SUPERVISION __Topic__WEAK_SUPERVISION__confidence  \\\n",
       "98                       None                                  None   \n",
       "422                      None                                  None   \n",
       "244                      None                                  None   \n",
       "203                      None                                  None   \n",
       "82                       None                                  None   \n",
       "\n",
       "                                          merged_texts  \n",
       "98   Real World Recommendation System - Part 1. Tra...  \n",
       "422  Meta has built a massive new language AI—and i...  \n",
       "244  Weaviate Podcast #9: Karen Beckers about the r...  \n",
       "203  Building systems to securely reason over priva...  \n",
       "82   Data Science at Stitch Fix. Podcast Interview ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_recommendations = df.loc[sorted_original_idxs[0:10]]\n",
    "top_10_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Topics covered by the article\n",
    "There are some problems when it comes to classifying topics in this setting. The most dominant one is that we don't know if the topics we selected are even all the topics that exist, for that we'd have to label every datapoint and also make sure that in the future there are no topics coming up that weren't in the training. Second, this data is rather unbalanced. We will not deal with these problems here and continue with our baseline usecase.\n",
    "\n",
    "Instead we will choose the topics that we want to have classified and which have enough support. We then introduce a \"catch-all\" class, where we map all other labels to.\n",
    "\n",
    "We will split the data into train and test set, train the model, and then evaluate it very quickly. We will not go into too much detail of the whole pipeline (it takes companies months to make sense of their data and models!) as this is not the aim of this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the labeled instances\n",
    "labeled_idxs = df[~df[\"__Topic__MANUAL\"].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "big tech                 27\n",
       "research  and science    20\n",
       "library/code             14\n",
       "social media              9\n",
       "jobs                      9\n",
       "data science              9\n",
       "ai art                    6\n",
       "programming               6\n",
       "mobile                    5\n",
       "advice                    4\n",
       "society                   2\n",
       "event                     1\n",
       "Name: __Topic__MANUAL, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look what labels have enough support\n",
    "df.loc[labeled_idxs][\"__Topic__MANUAL\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the labels that have enough support\n",
    "topics = [\"big tech\", \"research  and science\", \"library/code\", \"social media\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = df.loc[labeled_idxs]\n",
    "labeled_df = labeled_df[labeled_df[\"__Topic__MANUAL\"].isin(topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(labeled_df.index.tolist(), test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings[train_idx]\n",
    "X_test = embeddings[test_idx]\n",
    "y_train = df.loc[train_idx][\"__Topic__MANUAL\"]\n",
    "y_test = df.loc[test_idx][\"__Topic__MANUAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate a classifier\n",
    "We can simulate the classification layer of a typical BERT pipeline with a LogisticRegression sklearn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moe\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             big tech       0.80      1.00      0.89         4\n",
      "         library/code       1.00      1.00      1.00         3\n",
      "research  and science       1.00      0.80      0.89         5\n",
      "         social media       1.00      1.00      1.00         2\n",
      "\n",
      "             accuracy                           0.93        14\n",
      "            macro avg       0.95      0.95      0.94        14\n",
      "         weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moe\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(embeddings[labeled_df.index], labeled_df[\"__Topic__MANUAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unlabeled data\n",
    "unlabeled_df = df.drop(labeled_df.index)[\"__Topic__MANUAL\"]\n",
    "unlabeled_idxs = unlabeled_df.index\n",
    "\n",
    "X = embeddings[unlabeled_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_idx, pred_class = np.where(probs > 0.75)\n",
    "pred_class_text = list(map(lambda x: clf.classes_[x],pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic\"] = \"Unknown\"\n",
    "df.loc[labeled_df.index,\"topic\"] = df.loc[labeled_df.index][\"__Topic__MANUAL\"]\n",
    "df.loc[pred_idx,\"topic\"] = pred_class_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown                  314\n",
       "research  and science     91\n",
       "big tech                  83\n",
       "library/code              57\n",
       "social media               8\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data with predicted topics to disk\n",
    "df[['newsletter', 'date', 'headline', 'body', '__Interesting__MANUAL', 'merged_texts', 'topic']].to_csv(\"output.csv\", index=False, quoting=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('onetask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a8dd3a8ce1b4c991bd9fc20ecbd33bb3a991b4d95e67424ec48b6633f11a8d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
